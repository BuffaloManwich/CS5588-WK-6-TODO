{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f2519a2-2ce5-4127-a274-5b1852e7f865",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manny-buff/venvs/core-rag/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment probe written to: /home/manny-buff/projects/capstone/week6-rag-graph/configs/env_rag_graph.json\n",
      "{\n",
      "  \"python_venv\": \"/home/manny-buff/venvs/core-rag\",\n",
      "  \"python_version\": \"3.11.9\",\n",
      "  \"platform\": \"Linux-6.14.0-33-generic-x86_64-with-glibc2.39\",\n",
      "  \"cuda_visible_devices\": null,\n",
      "  \"nvidia_smi\": \"NVIDIA GeForce RTX 4080, 580.65.06, 16376 MiB\",\n",
      "  \"which_python\": \"/home/manny-buff/venvs/core-rag/bin/python\",\n",
      "  \"pip_freeze_head\": \"accelerate==1.10.1\\nacres==0.5.0\\naiofiles==24.1.0\\naiohappyeyeballs==2.6.1\\naiohttp==3.12.15\\naiosignal==1.4.0\\naiosqlite==0.21.0\\nannotated-types==0.7.0\\nanyio==4.10.0\\nargon2-cffi==25.1.0\\nargon2-cffi-bindings==25.1.0\\narrow==1.3.0\\nasttokens==3.0.0\\nasync-lru==2.0.5\\nattrs==25.3.0\\nav==15.1.0\\nbabel==2.17.0\\nbackoff==2.2.1\\nbanks==2.2.0\\nbcrypt==4.3.0\",\n",
      "  \"packages\": {\n",
      "    \"numpy\": \"2.2.1\",\n",
      "    \"pandas\": \"2.2.3\",\n",
      "    \"networkx\": \"3.3\",\n",
      "    \"sentence_transformers\": \"3.0.1\",\n",
      "    \"transformers\": \"4.56.2\",\n",
      "    \"accelerate\": \"1.10.1\",\n",
      "    \"faiss\": \"1.10.0\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "'Cell A: Environment Probe'\n",
    "Purpose:\n",
    "- Detect Python version, CUDA toolkits (if available), GPU info, and key package versions.\n",
    "- Save a merged record into configs/env_rag_graph.json for reproducibility.\n",
    "\n",
    "Notes:\n",
    "- Uses only standard libs + minimal imports to avoid heavy loads here.\n",
    "\"\"\"\n",
    "\n",
    "import json, os, sys, subprocess, shutil, platform\n",
    "from pathlib import Path\n",
    "\n",
    "# 'Paths and files' - adjust only if your project layout changes\n",
    "ROOT = Path(\"/home/manny-buff/projects/capstone/week6-rag-graph\")\n",
    "CFG  = ROOT / \"configs\" / \"env_rag_graph.json\"\n",
    "\n",
    "def cmd_out(args):\n",
    "    # 'Run a shell command safely and return stdout text'\n",
    "    try:\n",
    "        return subprocess.check_output(args, stderr=subprocess.STDOUT, text=True).strip()\n",
    "    except Exception as e:\n",
    "        return f\"ERROR: {e}\"\n",
    "\n",
    "# 'Collect environment info'\n",
    "info = {\n",
    "    \"python_venv\": str(Path.home() / \"venvs\" / \"core-rag\"),\n",
    "    \"python_version\": sys.version.split()[0],\n",
    "    \"platform\": platform.platform(),\n",
    "    \"cuda_visible_devices\": os.environ.get(\"CUDA_VISIBLE_DEVICES\", None),\n",
    "    \"nvidia_smi\": cmd_out([\"bash\", \"-lc\", \"nvidia-smi --query-gpu=name,driver_version,memory.total --format=csv,noheader\"]),\n",
    "    \"which_python\": cmd_out([\"bash\", \"-lc\", \"which python\"]),\n",
    "    \"pip_freeze_head\": cmd_out([\"bash\", \"-lc\", \"pip freeze | head -n 20\"])\n",
    "}\n",
    "\n",
    "# 'Key packages versions' - quick imports to record versions\n",
    "versions = {}\n",
    "for pkg in [\"numpy\", \"pandas\", \"networkx\", \"sentence_transformers\", \"transformers\", \"accelerate\", \"faiss\"]:\n",
    "    try:\n",
    "        mod = __import__(pkg)\n",
    "        versions[pkg] = getattr(mod, \"__version__\", \"unknown\")\n",
    "    except Exception as e:\n",
    "        versions[pkg] = f\"not importable: {e}\"\n",
    "\n",
    "info[\"packages\"] = versions\n",
    "\n",
    "# 'Merge with existing json'\n",
    "CFG.parent.mkdir(parents=True, exist_ok=True)\n",
    "existing = {}\n",
    "if CFG.exists():\n",
    "    try:\n",
    "        existing = json.loads(CFG.read_text())\n",
    "    except Exception:\n",
    "        existing = {}\n",
    "\n",
    "existing.update(info)\n",
    "CFG.write_text(json.dumps(existing, indent=2))\n",
    "\n",
    "print(\"Environment probe written to:\", CFG)\n",
    "print(json.dumps(info, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "857c4935-ca72-4e19-9a15-5e59bc9fe2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: (1, 384) dtype: float32\n",
      "Qwen local path: /home/manny-buff/projects/capstone/hw-rag/models/Qwen2-VL-2B-Instruct exists: True\n",
      "Graph nodes/edges: 3 2\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "'Cell B: Sanity Probe'\n",
    "Purpose:\n",
    "- Verify core imports.\n",
    "- Run a tiny e5 embedding call to confirm encoder works.\n",
    "- Check that local Qwen path exists (skip heavy model load for now).\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# 'Load run config'\n",
    "import json\n",
    "CFG_RUN = Path(\"/home/manny-buff/projects/capstone/week6-rag-graph/configs/rag_graph_run_config.json\")\n",
    "run_cfg = json.loads(CFG_RUN.read_text())\n",
    "\n",
    "# 'Imports check'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 'Embed a sample query with e5-small-v2'\n",
    "embed_model_id = run_cfg[\"embed_model\"]\n",
    "model = SentenceTransformer(embed_model_id)\n",
    "vec = model.encode([\"hello graph-rag world\"], convert_to_numpy=True)\n",
    "print(\"Embedding shape:\", vec.shape, \"dtype:\", vec.dtype)\n",
    "\n",
    "# 'Confirm local Qwen path exists'\n",
    "qwen_local = Path(run_cfg[\"llm_local_path\"])\n",
    "print(\"Qwen local path:\", qwen_local, \"exists:\", qwen_local.exists())\n",
    "\n",
    "# 'Lightweight graph sanity'\n",
    "G = nx.Graph()\n",
    "G.add_edge(\"doc_A\", \"doc_B\", weight=0.9)\n",
    "G.add_edge(\"doc_B\", \"doc_C\", weight=0.7)\n",
    "print(\"Graph nodes/edges:\", G.number_of_nodes(), G.number_of_edges())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3afb4a0-26d5-4307-a215-0e40cd247db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config loaded.\n",
      "CORPUS_ROOT = /home/manny-buff/projects/capstone/hw-rag/data\n",
      "Vector DB path = /home/manny-buff/projects/capstone/week6-rag-graph/artifacts/vdb\n",
      "Extensions searched: ['.csv', '.htm', '.html', '.json', '.md', '.pdf', '.text', '.txt']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "'Cell C: Config + Helpers (extended)'\n",
    "- Loads config.\n",
    "- Discovers multiple filetypes.\n",
    "- Extracts text from txt/md/text/pdf/json/csv/html/htm.\n",
    "- Adds a tqdm fallback and silences the common tqdm warning.\n",
    "\"\"\"\n",
    "\n",
    "import os, json, re, math, pickle, warnings\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "import pandas as pd\n",
    "\n",
    "# Silence noisy tqdm warnings if present\n",
    "warnings.filterwarnings(\"ignore\", message=\".*tqdm.*\")\n",
    "\n",
    "# --- Load run config ---\n",
    "RUN_CFG_PATH = Path(\"/home/manny-buff/projects/capstone/week6-rag-graph/configs/rag_graph_run_config.json\")\n",
    "cfg = json.loads(RUN_CFG_PATH.read_text())\n",
    "\n",
    "CORPUS_ROOT   = Path(cfg[\"corpus_root\"])\n",
    "VDB_DIR       = Path(cfg[\"vector_db_dir\"])\n",
    "EMBED_ID      = cfg[\"embed_model\"]\n",
    "LLM_MODEL_ID  = cfg[\"llm_model_id\"]\n",
    "LLM_LOCAL     = Path(cfg[\"llm_local_path\"])\n",
    "DEVICE        = cfg.get(\"device\", \"cuda\")\n",
    "RETRIEVER_K   = int(cfg.get(\"retriever_k\", 5))\n",
    "HOP_LIMIT     = int(cfg.get(\"hop_limit\", 2))\n",
    "\n",
    "VDB_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- Optional deps used if available ---\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except Exception:\n",
    "    def tqdm(x, **kw):  # no-op fallback\n",
    "        return x\n",
    "\n",
    "# PDF\n",
    "try:\n",
    "    from pypdf import PdfReader\n",
    "except Exception:\n",
    "    PdfReader = None\n",
    "\n",
    "# HTML\n",
    "try:\n",
    "    from bs4 import BeautifulSoup\n",
    "except Exception:\n",
    "    BeautifulSoup = None\n",
    "\n",
    "# --- File discovery ---\n",
    "EXTS = {\".txt\", \".md\", \".text\", \".pdf\", \".json\", \".csv\", \".html\", \".htm\"}\n",
    "\n",
    "def find_files(root: Path) -> List[Path]:\n",
    "    files = []\n",
    "    for p in root.rglob(\"*\"):\n",
    "        if p.is_file() and p.suffix.lower() in EXTS:\n",
    "            files.append(p)\n",
    "    files.sort()\n",
    "    return files\n",
    "\n",
    "# --- Loaders by type ---\n",
    "def load_text_plain(fp: Path) -> str:\n",
    "    try:\n",
    "        return fp.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    except Exception:\n",
    "        return fp.read_text(errors=\"ignore\")\n",
    "\n",
    "def load_text_pdf(fp: Path) -> str:\n",
    "    if PdfReader is None:\n",
    "        return \"\"\n",
    "    try:\n",
    "        out = []\n",
    "        reader = PdfReader(str(fp))\n",
    "        for page in reader.pages:\n",
    "            out.append(page.extract_text() or \"\")\n",
    "        return \"\\n\".join(out)\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "def load_text_json(fp: Path) -> str:\n",
    "    try:\n",
    "        obj = json.loads(fp.read_text(encoding=\"utf-8\", errors=\"ignore\"))\n",
    "        # Flatten string-like leaf values\n",
    "        def walk(x):\n",
    "            if isinstance(x, dict):\n",
    "                return \" \".join(walk(v) for v in x.values())\n",
    "            if isinstance(x, list):\n",
    "                return \" \".join(walk(v) for v in x)\n",
    "            if isinstance(x, (str, int, float, bool)):\n",
    "                return str(x)\n",
    "            return \"\"\n",
    "        return walk(obj)\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "def load_text_csv(fp: Path) -> str:\n",
    "    try:\n",
    "        df = pd.read_csv(fp, nrows=10000)  # cap large files\n",
    "        return \" \".join(map(str, df.astype(str).values.ravel().tolist()))\n",
    "    except Exception:\n",
    "        try:\n",
    "            df = pd.read_table(fp, nrows=10000)\n",
    "            return \" \".join(map(str, df.astype(str).values.ravel().tolist()))\n",
    "        except Exception:\n",
    "            return \"\"\n",
    "\n",
    "def load_text_html(fp: Path) -> str:\n",
    "    if BeautifulSoup is None:\n",
    "        return \"\"\n",
    "    try:\n",
    "        html = fp.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "        soup = BeautifulSoup(html, \"lxml\")\n",
    "        return soup.get_text(\" \", strip=True)\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "LOADERS = {\n",
    "    \".txt\":  load_text_plain,\n",
    "    \".md\":   load_text_plain,\n",
    "    \".text\": load_text_plain,\n",
    "    \".pdf\":  load_text_pdf,\n",
    "    \".json\": load_text_json,\n",
    "    \".csv\":  load_text_csv,\n",
    "    \".html\": load_text_html,\n",
    "    \".htm\":  load_text_html,\n",
    "}\n",
    "\n",
    "def normalize_ws(s: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", s).strip()\n",
    "\n",
    "def chunk_text(s: str, max_tokens: int = 180, overlap: int = 30) -> List[str]:\n",
    "    toks = s.split()\n",
    "    chunks = []\n",
    "    i = 0\n",
    "    while i < len(toks):\n",
    "        j = min(i + max_tokens, len(toks))\n",
    "        chunk = \" \".join(toks[i:j]).strip()\n",
    "        if chunk:\n",
    "            chunks.append(chunk)\n",
    "        if j == len(toks):\n",
    "            break\n",
    "        i = max(0, j - overlap)\n",
    "    return chunks\n",
    "\n",
    "# --- Artifact I/O ---\n",
    "ART_META   = VDB_DIR / \"chunks_meta.parquet\"\n",
    "ART_CHUNKS = VDB_DIR / \"chunks_text.pkl\"\n",
    "ART_FAISS  = VDB_DIR / \"faiss.index\"\n",
    "ART_GRAPH  = VDB_DIR / \"graph.pkl\"\n",
    "\n",
    "import pickle\n",
    "def save_chunks_text(chunks: List[str]):\n",
    "    with open(ART_CHUNKS, \"wb\") as f:\n",
    "        pickle.dump(chunks, f)\n",
    "\n",
    "def load_chunks_text() -> List[str]:\n",
    "    with open(ART_CHUNKS, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "print(\"Config loaded.\")\n",
    "print(\"CORPUS_ROOT =\", CORPUS_ROOT)\n",
    "print(\"Vector DB path =\", VDB_DIR)\n",
    "print(\"Extensions searched:\", sorted(EXTS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "433bbcc6-c899-452f-934a-5706a183c486",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading+Chunking:  71%|███████████████████████████████▊             | 12/17 [00:59<00:12,  2.58s/it]EOF marker not found\n",
      "Loading+Chunking: 100%|█████████████████████████████████████████████| 17/17 [01:01<00:00,  3.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs: 17 | Chunks: 4381\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb1455023a62431595c5bfb7e36de4ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/137 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings: (4381, 384) elapsed_sec: 4.4\n",
      "Saved:\n",
      " - /home/manny-buff/projects/capstone/week6-rag-graph/artifacts/vdb/chunks_meta.parquet\n",
      " - /home/manny-buff/projects/capstone/week6-rag-graph/artifacts/vdb/chunks_text.pkl\n",
      " - /home/manny-buff/projects/capstone/week6-rag-graph/artifacts/vdb/faiss.index\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "'Cell D (guarded): Build Embeddings + FAISS index'\n",
    "- Reads/discovers/loads multiple file types.\n",
    "- Chunks and embeds with e5-small-v2.\n",
    "- Builds FAISS IP index (cosine on normalized vectors).\n",
    "- Guards against empty corpus (prints message and returns early).\n",
    "\"\"\"\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np, time, faiss\n",
    "\n",
    "files = find_files(CORPUS_ROOT)\n",
    "records = []\n",
    "chunks_text = []\n",
    "\n",
    "for doc_id, fp in enumerate(tqdm(files, desc=\"Loading+Chunking\")):\n",
    "    loader = LOADERS.get(fp.suffix.lower(), load_text_plain)\n",
    "    raw = loader(fp)\n",
    "    text = normalize_ws(raw)\n",
    "    if not text:\n",
    "        continue\n",
    "    parts = chunk_text(text, max_tokens=180, overlap=30)\n",
    "    for k, ch in enumerate(parts):\n",
    "        records.append({\n",
    "            \"doc_id\": doc_id,\n",
    "            \"chunk_id\": len(chunks_text),\n",
    "            \"path\": str(fp),\n",
    "            \"chunk_idx\": k\n",
    "        })\n",
    "        chunks_text.append(ch)\n",
    "\n",
    "import pandas as pd\n",
    "meta_df = pd.DataFrame(records)\n",
    "print(f\"Docs: {len(files)} | Chunks: {len(chunks_text)}\")\n",
    "\n",
    "# Guard: no chunks → stop gracefully\n",
    "if len(chunks_text) == 0:\n",
    "    print(\"No chunks found. Please confirm corpus file types and that loaders extracted text.\")\n",
    "    # Tip for debugging: run the shell probe to see extensions/counts.\n",
    "    raise SystemExit\n",
    "\n",
    "# Embed\n",
    "model = SentenceTransformer(EMBED_ID)\n",
    "t0 = time.time()\n",
    "emb = model.encode(\n",
    "    chunks_text,\n",
    "    convert_to_numpy=True,\n",
    "    normalize_embeddings=True,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "print(\"Embeddings:\", emb.shape, \"elapsed_sec:\", round(time.time()-t0, 2))\n",
    "\n",
    "# Build FAISS\n",
    "dim = emb.shape[1]\n",
    "index = faiss.IndexFlatIP(dim)\n",
    "index.add(emb.astype(np.float32))\n",
    "\n",
    "# Save artifacts\n",
    "meta_df.to_parquet(ART_META, index=False)\n",
    "save_chunks_text(chunks_text)\n",
    "faiss.write_index(index, str(ART_FAISS))\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\" -\", ART_META)\n",
    "print(\" -\", ART_CHUNKS)\n",
    "print(\" -\", ART_FAISS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "939e1843-43da-48ca-bad9-62016dbf1d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph built.\n",
      "Nodes: 4381 Edges: 46574\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "'Cell E: Build Similarity Graph'\n",
    "Purpose:\n",
    "- Create a lightweight graph of chunk relationships using top-N cosine neighbors.\n",
    "- Collapses edges to doc-level (optional) or keeps chunk-level. We'll keep chunk-level for precision.\n",
    "- Save graph.pkl for later Multi-Hop traversal.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np, networkx as nx, faiss, math\n",
    "\n",
    "# Params for graph density\n",
    "TOP_NEIGHBORS = max(10, RETRIEVER_K * 3)  # small multiple of retriever_k\n",
    "\n",
    "# Load index and chunks\n",
    "index = faiss.read_index(str(ART_FAISS))\n",
    "chunks = load_chunks_text()\n",
    "meta  = pd.read_parquet(ART_META)\n",
    "\n",
    "# Query each vector against index to get neighbors (excluding self)\n",
    "D, I = index.search(emb.astype(np.float32), TOP_NEIGHBORS + 1)\n",
    "\n",
    "G = nx.Graph()\n",
    "for row_idx, nbrs in enumerate(I):\n",
    "    src = int(row_idx)\n",
    "    for rank, nb in enumerate(nbrs):\n",
    "        if nb == -1 or nb == src: \n",
    "            continue\n",
    "        w = float(D[row_idx, rank])\n",
    "        if w <= 0: \n",
    "            continue\n",
    "        # Add undirected edge with weight=max(existing,w)\n",
    "        if G.has_edge(src, nb):\n",
    "            if w > G[src][nb].get(\"weight\", 0.0):\n",
    "                G[src][nb][\"weight\"] = w\n",
    "        else:\n",
    "            G.add_edge(src, nb, weight=w)\n",
    "\n",
    "# Persist graph\n",
    "with open(ART_GRAPH, \"wb\") as f:\n",
    "    pickle.dump(G, f)\n",
    "\n",
    "print(\"Graph built.\")\n",
    "print(\"Nodes:\", G.number_of_nodes(), \"Edges:\", G.number_of_edges())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cb4d72e-a933-48fb-aadf-b356e294ac75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-k retrieved:\n",
      "[1] score=0.822 | /home/manny-buff/projects/capstone/hw-rag/data/1001 do-it-yourself hints & tips  tricks.pdf | chunk#1033 :: For inspecting a car's fi:ont and rear lights, p. 29, \"Night moves\" > Minor tUe for mounting on the ceil- ing of a closet to see what is …\n",
      "[2] score=0.815 | /home/manny-buff/projects/capstone/hw-rag/data/1001 do-it-yourself hints & tips  tricks.pdf | chunk#1008 :: for a child's dresser, p. 21, \"Playful pulls\" Aluminum foil >■ Wrapped around pillows, to keep cats off the sofa, p. 41, \"Stay off the …\n",
      "[3] score=0.815 | /home/manny-buff/projects/capstone/hw-rag/data/1001 do-it-yourself hints & tips  tricks.pdf | chunk#1030 :: pour before completion, p. 258, \"Easy pour\" >■ To prevent a toilet bowl from \"sweating\" m humid weather, p. 173, \"Bathroom condensation\" …\n",
      "[4] score=0.815 | /home/manny-buff/projects/capstone/hw-rag/data/the-complete-idiots-guide-to-simple-home-repair.pdf | chunk#26 :: motion. Warmest thanks are also due to Lynn Northrup, Jan Lynn, and Ross Patty, whose thoughtful suggestions and unflagging attention made …\n",
      "[5] score=0.812 | /home/manny-buff/projects/capstone/hw-rag/data/1001 do-it-yourself hints & tips  tricks.pdf | chunk#1036 :: \"Do the pan-pan\" Pants hanger, wood >• To store paper bags, p. 33, \"How to brown bag it?\" >• Filled with manure and j water, for …\n",
      "\n",
      "Graph neighbors (first 10) of top chunk: 1033\n",
      "Neighbors: [1012, 1019, np.int64(1051), np.int64(1042), np.int64(1034), np.int64(1043), np.int64(1032), np.int64(1023), np.int64(1048), np.int64(1018)]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "'Cell F: Validate'\n",
    "Purpose:\n",
    "- Issue a sample query to FAISS, print top-k chunk previews\n",
    "- Show 1-step neighbors in the graph for the top hit (sanity for Multi-Hop)\n",
    "\"\"\"\n",
    "\n",
    "import textwrap, faiss, numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "index = faiss.read_index(str(ART_FAISS))\n",
    "meta  = pd.read_parquet(ART_META)\n",
    "chunks = load_chunks_text()\n",
    "enc   = SentenceTransformer(EMBED_ID)\n",
    "\n",
    "query = \"Briefly summarize the core topic of this corpus.\"\n",
    "qv = enc.encode([query], convert_to_numpy=True, normalize_embeddings=True)\n",
    "D, I = index.search(qv.astype(np.float32), RETRIEVER_K)\n",
    "\n",
    "print(\"Top-k retrieved:\")\n",
    "for rank, cid in enumerate(I[0]):\n",
    "    doc = meta.loc[meta[\"chunk_id\"]==cid].iloc[0]\n",
    "    preview = textwrap.shorten(chunks[cid], width=140, placeholder=\" …\")\n",
    "    print(f\"[{rank+1}] score={D[0,rank]:.3f} | {doc['path']} | chunk#{doc['chunk_idx']} :: {preview}\")\n",
    "\n",
    "# Graph neighbor preview for top hit\n",
    "top_chunk = int(I[0,0])\n",
    "print(\"\\nGraph neighbors (first 10) of top chunk:\", top_chunk)\n",
    "with open(ART_GRAPH, \"rb\") as f:\n",
    "    G = pickle.load(f)\n",
    "nbrs = list(G.neighbors(top_chunk))[:10]\n",
    "print(\"Neighbors:\", nbrs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef0811e-362f-4e56-b3ab-1351b356ea44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Week 6 — Part 1: Graph-RAG Build (Summary)\n",
    "\n",
    "'''\n",
    "**Corpus**: 17 PDFs under `/home/manny-buff/projects/capstone/hw-rag/data/`  \n",
    "**Embedder**: `intfloat/e5-small-v2` (normalized vectors; cosine via FAISS IP)  \n",
    "**Index**: FAISS saved to `artifacts/vdb/faiss.index`  \n",
    "**Graph**: chunk-level similarity graph (NetworkX) using top-N neighbors; saved to `artifacts/vdb/graph.pkl`  \n",
    "**Chunks**: <auto-printed in Cell D>  \n",
    "**Graph Size**: <auto-printed in Cell E>  \n",
    "\n",
    "### Pipeline Steps\n",
    "1. **Load & Extract** text (txt/md/text/pdf/json/csv/html) with simple loaders (PDF via pypdf).\n",
    "2. **Chunk** with 180-token windows + 30 overlap.\n",
    "3. **Embed** chunks with e5-small-v2; normalize embeddings.\n",
    "4. **Index** with FAISS (Inner Product) → cosine on normalized vectors.\n",
    "5. **Graph**: for each chunk, connect to top neighbors with weight = similarity.\n",
    "\n",
    "### Validations\n",
    "- Retrieval preview (top-k) shows relevant chunks with file paths.\n",
    "- Graph neighbors displayed for top hit.\n",
    "\n",
    "**Artifacts** are deterministic given the corpus and config in `configs/rag_graph_run_config.json`.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ad1284-93cd-4f2f-a765-0bdc4e44773f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (core-rag)",
   "language": "python",
   "name": "core-rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
